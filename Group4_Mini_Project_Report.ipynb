{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amir-asari/AIDroneWorkshop-24-01-2022-/blob/main/Group4_Mini_Project_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mini Project 2023 (Facemask)**\n",
        "\n",
        "**Total marks: 30**\n",
        "\n",
        "**Group No.: 4**\n",
        "\n",
        "**Group Members:**\n",
        "\n",
        "1)Nur Arifah Ummaimah Binti Mohd Rosli\n",
        "\n",
        "2)Nur Aisyah Maisarah Binti Zaini\n",
        "\n",
        "3)Nabihah Binti Zulkarnain\n",
        "\n",
        "4)Shasmita Dev A/P Ramesh\n",
        "\n",
        "5)Parrvathavarthini A/P Paramasivam\n",
        "\n",
        "6)Al-Chnani Hayder Adnan Abed"
      ],
      "metadata": {
        "id": "MhJMpFuFWzCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chapter 1: Introduction**\n",
        "\n",
        "The widespread use of face masks become an integral part of the global response during the COVID-19 pandemic. To ensure compliance with mask-wearing protocols, it is crucial to develop robust and efficient methods for detecting individuals without masks. In this project, our group focuses on the specific task of \"Frontal VS Side View without Mask\" classification using a Convolutional Neural Network (CNN) transfer learning approach.\n",
        "\n",
        "By leveraging the power of CNNs, our group can exploit their ability to analyze visual data and extract meaningful features. In this case, we will employ the VGG16 model as our pre-trained network, benefiting from its excellent performance in image recognition tasks. Transfer learning enables us to build upon the learned representations of VGG16 and adapt them to our face mask detection challenge, specifically targeting frontal and side views of individuals without masks.\n",
        "\n",
        "To facilitate our project, our team has been provided with a dataset created by previous students, consisting of selfie images captured from different angles and perspectives. Our primary objective is to develop a code using the CNN transfer learning approach to accurately distinguish between frontal and side views of individuals without masks. By focusing on this aspect, our group can contribute to the development of a comprehensive face mask detection system that covers various scenarios and orientations.Throughout the project, we will implement the code using Python, taking inspiration from the concepts and techniques discussed in class. By following the established workflow and guidelines, the teams to achieve a high level of accuracy and robustness in our classification algorithm. Furthermore, we will explore different techniques for data preprocessing, model training, and evaluation to optimize our solution's performance."
      ],
      "metadata": {
        "id": "lUNS109pXsDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chapter 2: Methodology and Results**\n",
        "\n",
        "\n",
        "**70:30**\n",
        "\n",
        "Freeze parameters of all layers except the last layer: https://github.com/amir-asari/SEBB4083-Assignment2023/blob/main/Group4_70_30.ipynb\n",
        "\n",
        "Freeze parameters of all layers except the last and second layers: https://github.com/amir-asari/SEBB4083-Assignment2023/blob/main/Group4_70_30_layer_2.ipynb\n",
        "\n",
        "Freeze parameters of all layers except the last, second, and third layers: https://github.com/amir-asari/SEBB4083-Assignment2023/blob/main/Group4_70_30_layer_3.ipynb\n",
        "\n",
        "**80:20**\n",
        "\n",
        "Results for training and testing data of 80:20. And the results for augmentation\n",
        "https://github.com/amir-asari/SEBB4083-Assignment2023/blob/main/Group4_80_20_Augmentation.ipynb\n",
        "\n",
        "Freeze parameters of all layers except the last layer: https://github.com/amir-asari/SEBB4083-Assignment2023/blob/main/Group4_Assignment_Ai_(80_20).ipynb\n",
        "\n",
        "Freeze parameters of all layers except the last and second layers: https://github.com/amir-asari/SEBB4083-Assignment2023/blob/main/Group4_Assignment_Ai_(80_20)%5BFreeze_!_2%2Clast%5D.ipynb\n",
        "\n",
        "Freeze parameters of all layers except the last, second, and third layers: https://github.com/amir-asari/AIDroneWorkshop-24-01-2022-/blob/main/Group4_Assignment_Ai_(80_20)_%5BFreeze_!_3%2C2%2Clast%5D.ipynb\n",
        "\n",
        "**90:10**\n",
        "\n",
        "Freeze parameters of all layers except the last layer: https://github.com/amir-asari/AIDroneWorkshop-24-01-2022-/blob/main/Group4_Frontal_VS_Side_View_(without_mask)_(90_10)_(1).ipynb\n",
        "\n",
        "Freeze parameters of all layers except the last and second layers: https://github.com/amir-asari/AIDroneWorkshop-24-01-2022-/blob/main/Group4_Frontal_VS_Side_View_(without_mask)_(90_10)_(2).ipynb\n",
        "\n",
        "Freeze parameters of all layers except the last, second and third layers: https://github.com/amir-asari/SEBB4083-Assignment2023/blob/main/Group4_Frontal_VS_Side_View_(without_mask)_(90_10)_(3).ipynb"
      ],
      "metadata": {
        "id": "KYj1kKi3X5jP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n"
      ],
      "metadata": {
        "id": "KkeBmZYWDW8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up"
      ],
      "metadata": {
        "id": "BvV5GeYJDgJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## (write your codes here)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "LKl7vUc7Dhsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data from google drive link"
      ],
      "metadata": {
        "id": "DOMG7GZNDmdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 1JLxmrftssqDKPeyFFs_iMIy_Dio1727C"
      ],
      "metadata": {
        "id": "KoFxRuZNDtcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip downloaded file"
      ],
      "metadata": {
        "id": "5UxK0zYLD86D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/DatasetG6.zip','r') as zipObj:\n",
        "  zipObj.extractall()"
      ],
      "metadata": {
        "id": "G5lhaKGsECez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data using Keras utility\n",
        "\n",
        "Define parameters"
      ],
      "metadata": {
        "id": "idGTsuxOEilj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50 # mini-batch gradient descent\n",
        "img_height = 224\n",
        "img_width = 224"
      ],
      "metadata": {
        "id": "4T4nhcjLEqqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA SPLITTING\n",
        "\n",
        "case 1 70:30\n",
        "\n",
        "case 2 80:20\n",
        "\n",
        "case 3 90:10\n",
        "\n",
        "Once splitted, all data will saved in folder called training_data and testing_data\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hq8IHPqPFD2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your dataset directory\n",
        "dataset_dir = '/content/DatasetG6'\n",
        "\n",
        "# Define the path to the directory where you want to create the train and test folders\n",
        "output_dir = '/content/output'\n",
        "\n",
        "# Define the percentage of data to be used for testing\n",
        "test_split = 0.3\n",
        "\n",
        "# Get the list of subfolders in the dataset directory\n",
        "subfolders = [subfolder for subfolder in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, subfolder))]\n",
        "\n",
        "print(subfolders)\n",
        "\n",
        "# Define the train and test folder paths\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "\n",
        "# Delete train and test folders if they already exist\n",
        "if os.path.exists(train_dir):\n",
        "    shutil.rmtree(train_dir)\n",
        "if os.path.exists(test_dir):\n",
        "    shutil.rmtree(test_dir)\n",
        "\n",
        "# Create the train and test folders in the output directory\n",
        "os.makedirs(train_dir)\n",
        "os.makedirs(test_dir)\n",
        "\n",
        "# Iterate over each subfolder and split the images into train and test sets\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(dataset_dir, subfolder)\n",
        "    images = os.listdir(subfolder_path)\n",
        "    train_images, test_images = train_test_split(images, test_size=test_split, random_state=42)\n",
        "\n",
        "    # Create the subfolders inside train and test directories\n",
        "    train_subfolder_dir = os.path.join(train_dir, subfolder)\n",
        "    test_subfolder_dir = os.path.join(test_dir, subfolder)\n",
        "    os.makedirs(train_subfolder_dir)\n",
        "    os.makedirs(test_subfolder_dir)\n",
        "\n",
        "    # Move the train images to the train folder\n",
        "    for image in train_images:\n",
        "        src = os.path.join(subfolder_path, image)\n",
        "        dst = os.path.join(train_dir, subfolder, image)\n",
        "        print(src)\n",
        "        print(dst)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    # Move the test images to the test folder\n",
        "    for image in test_images:\n",
        "        src = os.path.join(subfolder_path, image)\n",
        "        dst = os.path.join(test_dir, subfolder, image)\n",
        "        shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "p42YxvFwF6Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the subfolder containing the images\n",
        "test_properlywear_path = '/content/output/test/Properly Wear'\n",
        "test_unproperlywear_path = '/content/output/test/Unproperly Wear'\n",
        "train_properlywear_path = '/content/output/train/Properly Wear'\n",
        "train_unproperlywear_path = '/content/output/train/Unproperly Wear'\n",
        "\n",
        "# Count the number of images in the subfolder\n",
        "num_images1 = len([name for name in os.listdir(test_properlywear_path) if os.path.isfile(os.path.join(test_properlywear_path, name))])\n",
        "num_images2 = len([name for name in os.listdir(test_unproperlywear_path) if os.path.isfile(os.path.join(test_unproperlywear_path, name))])\n",
        "num_images3 = len([name for name in os.listdir(train_properlywear_path) if os.path.isfile(os.path.join(train_properlywear_path, name))])\n",
        "num_images4 = len([name for name in os.listdir(train_unproperlywear_path) if os.path.isfile(os.path.join(train_unproperlywear_path, name))])\n",
        "\n",
        "# Print the number of images in the subfolder\n",
        "print(f\"Number of images in the test/Properly Wear: {num_images1}\")\n",
        "print(f\"Number of images in the test/Unproperly Wear: {num_images2}\")\n",
        "print(f\"Number of images in the train/test/Properly Wear: {num_images3}\")\n",
        "print(f\"Number of images in the train/test/UnProperly Wear: {num_images4}\")"
      ],
      "metadata": {
        "id": "RXYMqiJOGC9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_dir = '/content/DatasetG4'\n",
        "# train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "#   data_dir,\n",
        "#   validation_split=0.2,\n",
        "#   subset=\"training\",\n",
        "#   seed=123,\n",
        "#   shuffle=True,\n",
        "#   image_size=(img_height, img_width),\n",
        "#   batch_size=batch_size)\n",
        "\n",
        "\n",
        "# validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "#   data_dir,\n",
        "#   validation_split=0.2,\n",
        "#   subset=\"validation\",\n",
        "#   seed=123,\n",
        "#   shuffle=True,\n",
        "#   image_size=(img_height, img_width),\n",
        "#   batch_size=batch_size)\n",
        "\n",
        "\n",
        "# Create an instance of the ImageDataGenerator with for training and testing\n",
        "train_data_generator = ImageDataGenerator( validation_split=0.2) # 20% from training will be leaved out for validation\n",
        "test_data_generator = ImageDataGenerator()\n",
        "\n",
        "names = [\"Front View\" , \"Side View\"]  #make sure the spelling is similar to the folder name\n",
        "\n",
        "# Create the train batch generator\n",
        "train_batches = train_data_generator.flow_from_directory(\n",
        "    '/content/output/train',\n",
        "    target_size = (img_width,img_height),\n",
        "    class_mode = 'sparse', #make label as integer value\n",
        "    subset='training',\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        "    color_mode = \"rgb\",\n",
        "    classes = names\n",
        ")\n",
        "\n",
        "# Create the validation batch generator\n",
        "validation_batches = train_data_generator.flow_from_directory(\n",
        "    '/content/output/train',\n",
        "    target_size = (img_width,img_height),\n",
        "    class_mode = 'sparse', #make label as integer value\n",
        "    subset='validation',\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        "    color_mode = \"rgb\",\n",
        "    classes = names\n",
        ")\n",
        "\n",
        "\n",
        "# Create the test generator\n",
        "test_batches = test_data_generator.flow_from_directory(\n",
        "    '/content/output/test',\n",
        "    target_size = (224,224),\n",
        "    class_mode = 'sparse', #make label as integer value\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        "    color_mode = \"rgb\",\n",
        "    classes = names\n",
        ")"
      ],
      "metadata": {
        "id": "ZQSblB5QGgbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize data"
      ],
      "metadata": {
        "id": "wnwi9lc_GiMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "single_train_image_batch = train_batches.next()  #single_train_batch[0] -> image  single_train_batch [1] -> label\n",
        "batch_images = single_train_image_batch[0]\n",
        "batch_labels = single_train_image_batch[1]\n",
        "print(batch_images.shape)\n",
        "print(batch_labels.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(batch_images[i].astype(\"uint8\"))\n",
        "  plt.title(names[batch_labels[i].astype(\"int\")])\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "98EABAbGGlBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the base model from the pre-trained VGG16\n",
        "\n",
        "First, instantiate a VGG16 model pre-loaded with weights trained on ImageNet."
      ],
      "metadata": {
        "id": "G4lfcsBtG7uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.VGG16()\n",
        "\n",
        "# print(type(base_model))\n",
        "print(\"****VGG16 original network arhitecture****\")\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "YxNctggTHFAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(base_model, to_file = 'VGG16_basemodel.png', show_shapes = True)"
      ],
      "metadata": {
        "id": "rCe3J27THOko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WITHOUT DATA AUGMENTATION\n",
        "\n",
        "Model created by copying from the 1st layer to the 2nd last layer\n"
      ],
      "metadata": {
        "id": "vErxUmo5HInX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "for layer in base_model.layers[0:-1]:\n",
        "  model.add(layer)\n",
        "\n",
        "print(\"****model after removing copy all VGG16 layers and remove the last layer****\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "p-5W251LHneo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing the existing weights\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "print(model.summary())\n",
        "\n",
        "# Add the last layer with new dense layer with 2 outputs replacing the dense layer with 1000 outputs\n",
        "model.add(tf.keras.layers.Dense(2))\n",
        "\n",
        "print(\"****model after add new dense layer replacing the previous VGG16 last layer****\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "GDM4axpCHwi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Compiling the model before training it\n",
        "learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## Training the model\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=5,\n",
        "                    validation_data=validation_batches)"
      ],
      "metadata": {
        "id": "bpPV_7rDIFgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the learning curves"
      ],
      "metadata": {
        "id": "yLkyfkeqILSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting the learning curves\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eHvW8wKvIQeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing model"
      ],
      "metadata": {
        "id": "8xw7jXC5ISuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(test_batches.shape)\n",
        "test_loss, test_acc = model.evaluate(test_batches)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "EmWb7nneIYk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  true_label, img = true_label[i].astype(\"uint8\"), img[i].astype(\"uint8\")\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(img)\n",
        "  predicted_label = np.argmax(predictions_array[i])\n",
        "\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"Predicted label: {}  Actual label: {}   Prob:{:2.0f}%\".format(names[predicted_label],\n",
        "                                names[true_label],\n",
        "                                100*np.max(predictions_array)),\n",
        "                                color=color)\n",
        "\n",
        "\n",
        "single_test_image_batch = test_batches.next()\n",
        "predicted_label_prob = model(single_test_image_batch[0]) # single_test_image_batch[0] -> batches of images; single_test_image_batch[1] -> batches of label\n",
        "predicted_label_prob = tf.nn.softmax(predicted_label_prob)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "for index in range(9):\n",
        "  ax = plt.subplot(3, 3, index + 1)\n",
        "  plot_image(index,predicted_label_prob,single_test_image_batch[1],single_test_image_batch[0])\n",
        "  plt.title(\"Testing image index: {}\".format(index))"
      ],
      "metadata": {
        "id": "M0pPyZDQIjCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WITH DATA AUGMENTATION**\n",
        "\n",
        "Create an instance of the ImageDataGenerator with desired augmentation options for training and validation"
      ],
      "metadata": {
        "id": "GpHCEmHSIfs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_generator = ImageDataGenerator ( validation_split=0.2,\n",
        "                                          rotation_range = 20,\n",
        "                                          width_shift_range=0.2,\n",
        "                                          height_shift_range=0.2,\n",
        "                                          )\n",
        "\n",
        "# Create the train batch generator\n",
        "train_batches = train_data_generator.flow_from_directory(\n",
        "    '/content/output/train',\n",
        "    target_size = (img_width,img_height),\n",
        "    class_mode = 'sparse', #make label as integer value\n",
        "    subset='training',\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        "    color_mode = \"rgb\",\n",
        "    classes = names\n",
        ")"
      ],
      "metadata": {
        "id": "uf8gcmdgIzp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create our model by copying from the 1st layer to the 2nd last layer\n",
        "model = tf.keras.models.Sequential()\n",
        "for layer in base_model.layers[0:-1]:\n",
        "  model.add(layer)\n",
        "\n",
        "#Freezing the existing weights\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#Add new layer which will replace the previous VGG16 last layer\n",
        "model.add(tf.keras.layers.Dense(2))\n",
        "\n",
        "# Compile the model\n",
        "learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=5,\n",
        "                    validation_data=validation_batches)"
      ],
      "metadata": {
        "id": "tCjLYZzEJCiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the learning curve"
      ],
      "metadata": {
        "id": "L1PgLGvWJJvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting the learning curves\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ByMp4MEGJRVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model"
      ],
      "metadata": {
        "id": "-E0hCBZ-JXKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(test_batches.shape)\n",
        "test_loss, test_acc = model.evaluate(test_batches)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "SptZMTqNJZh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data visualization"
      ],
      "metadata": {
        "id": "dAhI2LQlJbfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  true_label, img = true_label[i].astype(\"uint8\"), img[i].astype(\"uint8\")\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(img)\n",
        "  predicted_label = np.argmax(predictions_array[i])\n",
        "\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"Predicted label: {}  Actual label: {}   Prob:{:2.0f}%\".format(names[predicted_label],\n",
        "                                names[true_label],\n",
        "                                100*np.max(predictions_array)),\n",
        "                                color=color)\n",
        "\n",
        "\n",
        "single_test_image_batch = test_batches.next()\n",
        "predicted_label_prob = model(single_test_image_batch[0]) # single_test_image_batch[0] -> batches of images; single_test_image_batch[1] -> batches of label\n",
        "predicted_label_prob = tf.nn.softmax(predicted_label_prob)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for index in range(9):\n",
        "  ax = plt.subplot(3, 3, index + 1)\n",
        "  plot_image(index,predicted_label_prob,single_test_image_batch[1],single_test_image_batch[0])\n",
        "  plt.title(\"Testing image index: {}\".format(index))"
      ],
      "metadata": {
        "id": "f5afUd5aJflx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freezing except last layer\n",
        "\n",
        "Recreate the model from VGG16"
      ],
      "metadata": {
        "id": "0O0VG-Q5Jj3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create our model by copying from the 1st layer to the 2nd last layer\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "for layer in base_model.layers[0:-1]:\n",
        "  model.add(layer)"
      ],
      "metadata": {
        "id": "tSnmih59JzuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freezen some layers and add last laser with dense layer (2 outputs)\n"
      ],
      "metadata": {
        "id": "teIX2nhwJ4UU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Freezing the existing weights\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#add new layer which will replace the previous VGG16 last layer\n",
        "model.add(tf.keras.layers.Dense(2))"
      ],
      "metadata": {
        "id": "330Jd4ZIKAlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complile the model"
      ],
      "metadata": {
        "id": "FrkYveEcKHhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Eg0BWcQ2KTtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "Dm3luPBIKeGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_batches,\n",
        "                    epochs=5,\n",
        "                    validation_data=validation_batches)"
      ],
      "metadata": {
        "id": "YM2ICcG5KvUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Curve"
      ],
      "metadata": {
        "id": "b1ONeecmK-Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8KcMmnUrLDVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test model"
      ],
      "metadata": {
        "id": "jGkRzLnbLMlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(test_batches.shape)\n",
        "test_loss, test_acc = model.evaluate(test_batches)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "jNe1VdITLO8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize data"
      ],
      "metadata": {
        "id": "EzOzlPQLLRdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  true_label, img = true_label[i].astype(\"uint8\"), img[i].astype(\"uint8\")\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(img)\n",
        "  predicted_label = np.argmax(predictions_array[i])\n",
        "\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"Predicted label: {}  Actual label: {}   Prob:{:2.0f}%\".format(names[predicted_label],\n",
        "                                names[true_label],\n",
        "                                100*np.max(predictions_array)),\n",
        "                                color=color)\n",
        "\n",
        "\n",
        "single_test_image_batch = test_batches.next()\n",
        "predicted_label_prob = model(single_test_image_batch[0]) # single_test_image_batch[0] -> batches of images; single_test_image_batch[1] -> batches of label\n",
        "predicted_label_prob = tf.nn.softmax(predicted_label_prob)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for index in range(9):\n",
        "  ax = plt.subplot(3, 3, index + 1)\n",
        "  plot_image(index,predicted_label_prob,single_test_image_batch[1],single_test_image_batch[0])\n",
        "  plt.title(\"Testing image index: {}\".format(index))"
      ],
      "metadata": {
        "id": "U8FP9VrCLWRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze parameters of all layers except the last and second layers\n",
        "\n",
        "Create our model by copying from the 1st layer to the 3rd last layer"
      ],
      "metadata": {
        "id": "3RigfjmdL5Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "for layer in base_model.layers[0:-1]:\n",
        "  model.add(layer)\n",
        "\n",
        "  #Freezing the existing weights\n",
        "for layer in model.layers[0:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "#add new layer which will replace the previous VGG16 last layer\n",
        "model.add(tf.keras.layers.Dense(2))"
      ],
      "metadata": {
        "id": "ua5_M5sXM4ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and Train model"
      ],
      "metadata": {
        "id": "fyiGyOevM9T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=5,\n",
        "                    validation_data=validation_batches)"
      ],
      "metadata": {
        "id": "nuU1byNBNCJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the learning curve"
      ],
      "metadata": {
        "id": "mLa_YD4eNKsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting the learning curve\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2mVpVurnNRom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing model"
      ],
      "metadata": {
        "id": "H_xhGKOvNaWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(test_batches.shape)\n",
        "test_loss, test_acc = model.evaluate(test_batches)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "tvsyO7q0NeeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data visualisation"
      ],
      "metadata": {
        "id": "_v7A2dnLNgAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  true_label, img = true_label[i].astype(\"uint8\"), img[i].astype(\"uint8\")\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(img)\n",
        "  predicted_label = np.argmax(predictions_array[i])\n",
        "\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"Predicted label: {}  Actual label: {}   Prob:{:2.0f}%\".format(names[predicted_label],\n",
        "                                names[true_label],\n",
        "                                100*np.max(predictions_array)),\n",
        "                                color=color)\n",
        "\n",
        "\n",
        "single_test_image_batch = test_batches.next()\n",
        "predicted_label_prob = model(single_test_image_batch[0]) # single_test_image_batch[0] -> batches of images; single_test_image_batch[1] -> batches of label\n",
        "predicted_label_prob = tf.nn.softmax(predicted_label_prob)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for index in range(9):\n",
        "  ax = plt.subplot(3, 3, index + 1)\n",
        "  plot_image(index,predicted_label_prob,single_test_image_batch[1],single_test_image_batch[0])\n",
        "  plt.title(\"Testing image index: {}\".format(index))"
      ],
      "metadata": {
        "id": "xtNy4cFONk7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze parameters of all layers except the last, second and third layers"
      ],
      "metadata": {
        "id": "lIUbIqQENtw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create our model by copying from the 1st layer to the 4th last layer\n"
      ],
      "metadata": {
        "id": "BHBEc1vbN_2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "for layer in base_model.layers[0:-1]:\n",
        "  model.add(layer)\n",
        "\n",
        "  #Freezing the existing weights\n",
        "for layer in model.layers[0:-2]:\n",
        "    layer.trainable = False\n",
        "\n",
        "#add new layer which will replace the previous VGG16 last layer\n",
        "model.add(tf.keras.layers.Dense(2))"
      ],
      "metadata": {
        "id": "Do54i_-YN3dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling and train the model"
      ],
      "metadata": {
        "id": "3_JX6HSkOHee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=5,\n",
        "                    validation_data=validation_batches)"
      ],
      "metadata": {
        "id": "hHlIYhMROK1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the learning curve"
      ],
      "metadata": {
        "id": "1MlE4KOOOOaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cPoAPq4OOS-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing model"
      ],
      "metadata": {
        "id": "OzNO6xn6OapT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(test_batches.shape)\n",
        "test_loss, test_acc = model.evaluate(test_batches)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "rRUoOnf3Oda6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data visualization"
      ],
      "metadata": {
        "id": "uwWFXFAXOeaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  true_label, img = true_label[i].astype(\"uint8\"), img[i].astype(\"uint8\")\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(img)\n",
        "  predicted_label = np.argmax(predictions_array[i])\n",
        "\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"Predicted label: {}  Actual label: {}   Prob:{:2.0f}%\".format(names[predicted_label],\n",
        "                                names[true_label],\n",
        "                                100*np.max(predictions_array)),\n",
        "                                color=color)\n",
        "\n",
        "\n",
        "single_test_image_batch = test_batches.next()\n",
        "predicted_label_prob = model(single_test_image_batch[0]) # single_test_image_batch[0] -> batches of images; single_test_image_batch[1] -> batches of label\n",
        "predicted_label_prob = tf.nn.softmax(predicted_label_prob)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for index in range(9):\n",
        "  ax = plt.subplot(3, 3, index + 1)\n",
        "  plot_image(index,predicted_label_prob,single_test_image_batch[1],single_test_image_batch[0])\n",
        "  plt.title(\"Testing image index: {}\".format(index))"
      ],
      "metadata": {
        "id": "6Cvq5BseOm5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chapter 3: Discussion**\n",
        "\n",
        "**70:30**\n",
        "\n",
        "Based on the result, for the first part that freeze parameters of all layers except the last layer  the model with using data augmentation have higher accurancy compare to the model without using data augmentation. The highest test accurancy can achieve to 99% for model with data augementation and 98% for model without augementation. Data augmentation can improve the accurancy because it can help in overfitting but sometimes data augmentation is not necessary. (Poojary, 2021). For the step that, freeze parameters of all layers except the last, second, and third layers,the test accurancy for with augmentation is 98% while without augmentation is 99%. Generally, freezing more layers can help retain the pre-trained features and prevent overfitting, while allowing more layers to be updated provides the flexibility to adapt the model to the new task.\n",
        "\n",
        "**80:20**\n",
        "\n",
        "> When comparing the model **with data augmentation and without data augmentation** it could be observed that without using data augmentation the model was able to execute with a higher training and testing accuracy. However, there are other things that need to be considered such as the training curve. For the model without data augmentation, from the training curve it could be observed that during training there is an increase in accuracy over the epochs which indicates the model is improving the learning in every training’s repetition. The training loss decreases over the epochs and is lower than validity loss which indicates that the model has a good accuracy with the test accuracy of **0.9933 or 99.33%.** While, for the model with data augmentation: From the training curve it could be observed that during training there is a slight increase in accuracy over the epochs which indicates the model is improving the learning in every training’s repetition. The training loss decreases over the epochs and is lower than validity loss which indicates that the model has a good accuracy with the test accuracy of **0.9866 or 98.66%.** Compared to without data augmentation, the gap between validation and training accuracy in models with data augmentation suggest that the model is more accurate (Krizhevsky et al., n.d.,) and overfitting might not occur in the model.\n",
        "\n",
        "*   Next is the analysation on different freezing layers without data augmentation:\n",
        "\n",
        "**Freeze except last layer**\n",
        "\n",
        ">From the training curve it could be observed that during training there is an increase followed by linear progression of accuracy over the epochs which indicates there is no improvement and deterioration of learning in the model. Which means the model does not learn or improve its performance or overfitting occurs. Although the training accuracy and loss is higher and lower than validity respectively, the model is unable to capture the patterns in the data effectively. Furthermore, since there’s a slight gap between training and validation accuracy, there might be overfitting in the model.\n",
        "\n",
        "*Model Accuracy: 0.9983 or 99.83%*\n",
        "\n",
        "**Freeze except second last and last layer**\n",
        "\n",
        ">From the training curve it could be observed that there’s fluctuation in the training and validation accuracy which might be due to the model’s instability. Model’s instability can be caused from several factors such as high learning rate and insufficient learning data (Brownlee, 2016). Observing the training loss and validation loss it could be seen that the training loss is significantly lower than the validation loss which indicates that the model is improving based on the training data. However, there is a significant gap between both the training and validation loss which might suggest an overfitting in the model (Brownlee, 2016).\n",
        "\n",
        "*Model Accuracy: 0.9866 or 98.66%*\n",
        "\n",
        "**Freeze except second last, third last and last layer**\n",
        "\n",
        ">From the training curve it could be observed that there’s an increase in the model’s training accuracy. However, the gap between training and validity accuracy is quite big which suggests that the model might have an overfitting or other factors such as inadequate model capacity and hyperparameter tuning (Goodfellow et al., 2016). Observing the training loss and validation loss it could be seen that the training loss is significantly lower than the validation loss which indicates that the model is improving based on the training data. However, there is a significant gap between both the training and validation loss which might suggest an overfitting in the model (Goodfellow et al., 2016).\n",
        "\n",
        "*Model Accuracy: 0.9865 or 98.65%*\n",
        "\n",
        "*   Next is the analysation on different freezing layers with data augmentation:\n",
        "\n",
        "**Freeze except last layer**\n",
        "\n",
        ">From the training curve it could be observed that there is an increase in both the training and validation accuracy which suggest the model is improving and learning. However the gap between training and validation might suggest that there is overfitting in the model. The training loss is also lower than validation loss which indicates that the model is learning and improving over the epochs.\n",
        "\n",
        "*Model Accuracy: 0.9916 or 99.16%*\n",
        "\n",
        "**Freeze except second last and last layer**\n",
        "\n",
        ">From the training curve it could be observed that during training there is an increase in training accuracy over the epochs. However, there’s also fluctuation in the validation accuracy which might suggest that the validation set is rather small or the model is overfit (Goodfellow et al., 2016). Meanwhile, the training loss decreases over epochs but is higher than validation loss.  If the training loss is higher than the validation loss it might suggest that the model has an overfitting (Goodfellow et al., 2016).\n",
        "\n",
        "*Model Accuracy: 1.000 or 100%*\n",
        "\n",
        "**Freeze except second last, third last and last layer**\n",
        "\n",
        ">Accuracy: From the training curve it could be observed that although the training loss increases over epochs but it is still lower than validation accuracy. Due to the freezing of certain layers it hinders the model’s ability to learn from the training data which leads to lower training accuracy (Goodfellow et al., 2016). Meanwhile, the training loss decreases over epochs but is higher than validation loss.  If the training loss is higher than the validation loss it might suggest that the model has an overfitting (Goodfellow et al., 2016).\n",
        "\n",
        "*Model Accuracy: 0.9983 or 99.83%*\n",
        "\n",
        "**90:20**\n",
        "\n",
        "In the 90:10 split, the first configuration, which did not use any data augmentation and which frozen all layers but the last one, produced a test accuracy of 100%, while the second configuration, which used data augmentation to freeze all layers but the last one, produced a test accuracy of 99%. Additionally, the third configuration, which involved freezing all layers but the final two, produced the best outcomes with a test accuracy of 100%. Similar to the third configuration, the fourth configuration showed a high test accuracy of 99.67% by freezing all layers except the final three. Since the training data used was relatively extensive (Shah, 2023) and was able to provide a high percentage of test accuracy, the results generally imply that data augmentation is not a necessary step.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NC7ulXXfYDga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chapter 4: Conclusion**\n",
        "\n",
        "This project presents the development of an automated classification algorithm for face detection. The approach used in this study involves utilising a Convolutional Neural Network (CNN) transfer learning technique, specifically utilising the VGG16 pre-trained model. The present study examines a dataset comprising a diverse range of selfie pictures captured under various conditions. These conditions encompass front view, side view, near to camera view, far to camera view\n",
        "\n",
        "For the first task, the hyperparameters fixed and divided the dataset into training and testing splits that were 70:30 each. The trained model performed well in classifying photos of face , as evidenced by its accuracy and loss on the test data. This highlights the capacity of the CNN transfer learning approach to efficiently learn from the dataset and generalise, resulting in acceptable face detection results.\n",
        "\n",
        "\n",
        "The algorithm's results with and without data augmentation was compared in the second task. Techniques for enhancing the data were used during training to broaden the training set's diversity. In comparison to the model without augmentation, the model trained with it performed better. Changes were added to the training photos by enhancing the data, which helped the model learn and generalise to new data more effectively. This emphasises how crucial data augmentation is to strengthening the reliability and precision of the face detection system.\n",
        "\n",
        "In the third task, VGG16 model's was experimented with freezing different sets of parameters . When parameters are frozen, updates to them are stopped during training so that only the unfrozen layers are trained. Three situations were examined: freezing all layers but the topmost layer; freezing all layers but the topmost and second-to-last layers; and freezing all layers but the topmost, second-to-last layers. In comparison to freezing more layers (last, second, and third layers), the results showed that freezing fewer layers (final layer only or last and second layers) led to higher performance. This shows that the pre-trained model's bottom layers capture traits that are more broad and useful for the job of detecting face.\n",
        "\n",
        "In conclusion, the choice of data augmentation and the freezing of parameters in the VGG16 transfer learning approach for face detection depend on the specific dataset and task requirements. Data augmentation can be beneficial in improving accuracy, especially when training data is limited. However, with a sufficient amount of training data, freezing fewer layers while retaining the pre-trained features can lead to high accuracy results. Overall, this project demonstrates the importance of evaluating different configurations and considering the characteristics of the dataset to optimize the performance of the face detection algorithm.Transfer learning, data augmentation, and parameter freezing worked well together to create a reliable and accurate classification method. Automated face detection can help with monitoring compliance and enforcing safety regulations, which has practical consequences for public health and safety.\n"
      ],
      "metadata": {
        "id": "6Fn90k0YYNwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reference**"
      ],
      "metadata": {
        "id": "X-KwoJBnYRyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Poojary, R., Raina, R., & Mondal, A. K. (2021). Effect of\n",
        "data-augmentation on fine-tuned CNN model performance. IAES International Journal of Artificial Intelligence, 10(1), 84.\n",
        "\n",
        "Brownlee, J. (2016, March 21). Overfitting and Underfitting With Machine Learning Algorithms - MachineLearningMastery.com. Machine Learning Mastery. Retrieved July 2, 2023, from https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/\n",
        "\n",
        "Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\n",
        "\n",
        "Krizhevsky, A., Sutskever, I., & Hinton, G. E. (n.d.). ImageNet Classification with Deep Convolutional Neural Networks. Communications of the ACM, 60(6), 84-90. https://dl.acm.org/doi/abs/10.1145/3065386"
      ],
      "metadata": {
        "id": "W7AeoRHKNoUe"
      }
    }
  ]
}